# Entropía

![[Pasted image 20230319212503.png]]

![[Pasted image 20230319212513.png]]

```ad-quote
title: Diapositivas
collapse: closed
![[Pasted image 20230319212845.png]]

![[Pasted image 20230319220218.png]]

![[Pasted image 20230319220306.png]]
```

## Entropía como función de una distribución

![[Pasted image 20230319213003.png]]

## Entropía conjunta y condicional

![[Pasted image 20230319213111.png]]

![[Pasted image 20230319213121.png]]

## Regla de la cadena para la entropía

![[Pasted image 20230319213158.png]]

![[Pasted image 20230319213207.png]]

### Caso condicionado
![[Pasted image 20230319213217.png]]

### Caso general
![[Pasted image 20230319213242.png]]

#### No condicionado
![[Pasted image 20230319213253.png]]

#### Condicionado
![[Pasted image 20230319213425.png]]

### Ejemplo
![[Pasted image 20230319213521.png]]


# Divergencia, Entropía Relativa o Distancia LK

![[Pasted image 20230319212616.png]]

```ad-cite
title: Diapositivas
collapse: closed
![[Pasted image 20230319213640.png]]
```

## Entropía relativa conjunta y condicional

![[Pasted image 20230319215455.png]]

![[Pasted image 20230319215512.png]]

### Regla de la cadena

![[Pasted image 20230319215625.png]]

![[Pasted image 20230319215634.png]]

## Desigualdad de la información

![[Pasted image 20230319215754.png]]

![[Pasted image 20230319215802.png]]

![[Pasted image 20230319215808.png]]

#### En divergencia condicional

![[Pasted image 20230319215834.png]]

![[Pasted image 20230319215842.png]]

## Entropía máxima

![[Pasted image 20230319215919.png]]

![[Pasted image 20230319215926.png]]


# Información mutua

![[Pasted image 20230319212557.png]]

![[Pasted image 20230319212628.png]]

![[Pasted image 20230320210519.png]]

```ad-quote
title: Diapositivas
collapse: closed
![[Pasted image 20230319220030.png]]
```

## Informacion mutua condicional
$$I(X;Y|Z) = H(X|Z) - H(X|Y, Z)$$

## Más importante:
- $I(X;Y) = H(X) + H(Y) - H(X, Y)$
- $I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)$

# Reglas de la cadena

![[Pasted image 20230319212640.png]]
Caso base: $$I(X, Y; Z) = I(X; Z) + I(Y; Z| X)$$
![[Pasted image 20230319212649.png]]
# Desigualdades

![[Pasted image 20230319212704.png]]

# Cota de Independencia

![[Pasted image 20230321230903.png]]