{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "### Aprendizaje Autom√°tico - Instituto de Computaci√≥n - UdelaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a Mauricio Delbracio (@2ptmvd) por varias de las im√°genes e ideas para esta presentaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Tensorflow Playground](https://playground.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "Retomando la √∫ltima slide de la clase de redes neuronales...  \n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/mitchell_rep_learning.png\" alt=\"Rep.Learning\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "\n",
    "> ‚ÄúDeep learning allows computational models that are composed of\n",
    "> multiple processing layers to learn representations of data with\n",
    "> multiple levels of abstraction.‚Äù\n",
    "\n",
    "<div align=\"right\">Yann LeCun, Yoshua Bengio and Geoffrey Hinton, Deep Learning, Nature, 2015</div>\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/science_2015.png\" alt=\"Science 2015\" width=700 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning\n",
    "\n",
    "- Redes con muchas capas no lineales en cascada\n",
    "- Cada capa usa la salida de la capa anterior como entrada, y obtiene representaciones con mayor nivel de abstracci√≥n \n",
    "- Busca generar una jerarqu√≠a de conceptos en las diferentes capas\n",
    "- Las representaciones de bajo nivel son comunes a las distintas categor√≠as\n",
    "- Las representaciones de alto nivel son m√°s globales, y m√°s invariantes\n",
    "- Im√°genes: Pixel $\\to$ bordes $\\to$ partes $\\to$ objetos\n",
    "- Entrenamiento punta a punta\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/ff_network_cat.png\" alt=\"Hidden cat\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "- ML tradicional: clasificadores lineales sobre atributos hechos \"a mano\". \n",
    "\n",
    "- Problema m√°s dif√≠ciles: reconocimiento de im√°genes, sonido\n",
    "    - Robustos a variaciones\n",
    "    - Sensibles a variaciones m√≠nimas \n",
    "    \n",
    "- Soluci√≥n: stack de capas, varias de las cuales computan mapeos no lineales entre entradas y salidas\n",
    "    - Cada capa mejora la selectividad (distinguir gatos de animales parecidos) y la invarianza (identificar diferentes gatos, con diferencias de luz o de poses, por ejemplo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Un poco de historia... \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/deep_learning_history_andrew_beam.jpg\" alt=\"Deep Learning History\"  />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redes Feedforward\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/red_feedforward.png\" alt=\"Feedforward networks\" width=450 />\n",
    "\n",
    "- Cada conjunto de neuronas computa la suma ponderada de sus entradas y lo pasa por una funci√≥n no lineal (e.g. ReLU)\n",
    "- No hay retroalimentaci√≥n\n",
    "- Aprendizaje basado en optimizaci√≥n (Backpropagation y descenso por gradiente estoc√°stico)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Teorema de Aproximaci√≥n Universal\n",
    "\n",
    "> Una red neuronal feedforward con una √∫nica capa oculta y un n√∫mero finito de neuronas puede aproximar cualquier funci√≥n continua en un espacio compacto de $\\mathbb{R}^n$\n",
    ">\n",
    ">                                                                (Cybenko, 1989; Hornik 1991)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "- Si encontramos los par√°metros, podemos representar gran variedad de funciones\n",
    "- El teorema no habla de _c√≥mo_ aprender los par√°metros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas de las redes FF\n",
    "\n",
    "- Much√≠simos par√°metros: sobreajuste üòà\n",
    "- Dif√≠ciles de entrenar: inicializaci√≥n, costo computacional\n",
    "\n",
    "- Soluci√≥n: forzar invarianzas en la arquitectura, reduciendo el n√∫mero de par√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- Algoritmo de deep learning que toma una imagen (o similar), asigna pesos a diferentes caracter√≠sticas, y permite diferenciarlas\n",
    "- Aprenden las caracter√≠sticas a partir de ejemplos\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/cnn_general.jpeg\" alt=\"Feedforward networks\" width=650 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- ¬øQu√© es una convoluci√≥n? [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA), por Gran Sanderson\n",
    "\n",
    "- Operaci√≥n lineal entre una imagen y un filtro, que devuelve una nueva imagen\n",
    "\n",
    "<img src=\"https://docs.gimp.org/2.8/en/images/filters/examples/convolution-calculate.png\" alt=\"Convolution\" width=600 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- ¬øQu√© es una convoluci√≥n?\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/edge_detect.png\" alt=\"Convolution\" width=700/>\n",
    "\n",
    "(M√°s ejemplos, en los manuales de [GIMP](https://docs.gimp.org/2.8/en/plug-in-convmatrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- ¬øQu√© es una convoluci√≥n?\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/convolution_image.png\" alt=\"Convolution\"  width=700 />\n",
    "\n",
    "- Las convoluciones pueden darnos una idea de partes \"importantes\" de la imagen(e.g. bordes)\n",
    "- N√≥tese que todos los cambios dependen solamente del filtro\n",
    "\n",
    "[Image kernels explained visually](https://setosa.io/ev/image-kernels/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/activation_map.png\" alt=\"Convolution\"  width=700 />\n",
    "\n",
    " <div align=\"right\">(Im√°genes del curso de \"Aprendizaje profundo para visi√≥n artificial\")</div>\n",
    "\n",
    "- Se impone (en lugar de aprenderla) la invarianza a traslaci√≥n $\\to$\n",
    "- Se comparten pesos, bajando el n√∫mero de par√°metros\n",
    "- Las caracter√≠sticas de bajo nivel son locales (el filtro refire a unos pocos p√≠xeles alrededor)\n",
    "- Submuestreamos al seguir avanzando en la red, para reducir a√∫n m√°s los par√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/cnn_curso_iie1.png\" alt=\"Convolution\"  width=700 />\n",
    "\n",
    "- En cada capa, la nueva imagen s√≥lo depende de los pesos del filtro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/cnn_curso_iie2.png\" alt=\"Convolution\"  width=700 />\n",
    "\n",
    "- Cada filtro se va a especializar en algo distinto (dependiendo los pesos iniciales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/conv_activacion.png\" alt=\"Convolution\"  width=600 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/max_pooling.png\" alt=\"Convolution\"  width=600 />\n",
    "\n",
    "- La capa de pooling permite submuestrear la imagen, reduciendo el tama√±o, conservando caracter√≠sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/pooling.png\" alt=\"Convolution\"  width=600 />\n",
    "\n",
    "- Hip√≥tesis: las caracter√≠sticas de m√°s alto nivel son m√°s gen√©ricas (y por lo tanto necesitamos menos par√°metros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Lenet-5 - 1998\n",
    " \n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/lenet-5.png\" alt=\"Convolution\" width=800   />\n",
    "\n",
    "- [LeCun, Y., Bottou, L., Bengio, Y. and Haffner, P. ‚ÄúGradient-based learning applied to document recognition.‚Äù Proc. IEEE (1998)](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
    "- Aplicada al reconocimiento de d√≠gitos escritos a mano\n",
    "- Faltaba hardware, especialmente GPUs, por lo que no funcionaba tan bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AlexNet - 2012\n",
    " \n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/alexnet.png\" alt=\"Convolution\"  width=800 />\n",
    "\n",
    "- [Krizhevsky, Alex, Ilya Sutskever, Geoffrey E. Hinton.\n",
    "Imagenet classification with deep convolutional neural networks, NIPS 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- Entrenada a partir de [ImageNet](http://www.image-net.org/) (1 mill√≥n de im√°genes, 1.000 categor√≠as)\n",
    "- Tasa de error: 37.5% (top-1) y 17% (top-5), 10 puntos menos que el estado del arte al momento\n",
    "- En 2017, 29 de los 38 equipos de la competencia ten√≠an accuracy mayor a 95%\n",
    "- Hoy, ImageNet tiene 14 millones de im√°genes, con 20.000 categor√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning para el Procesamiento de Lenguaje Natural (Jurafsky & Martin)\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/neural_language_model.png\" alt=\"Neural Language Model\"  width=400 /> \n",
    "- Entrenar una red neuronal para que, a partir una secuencia de palabras, prediga la siguiente (modelo de lenguaje).\n",
    "- Las palabras de la entrada se representan con vectores one-hot\n",
    "- Los pesos de la primera capa pueden verse como representaciones densas de la palabra\n",
    "- Capturan relaciones no expl√≠citas, solamente a partir del contexto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Word Embeddings \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/one_hot_versus_dense_embeddings.png\" alt=\"Dense embeddings\" width=200  /><div align=\"right\">(Imagen tomadas de Fran√ßois Chollet with J. J. Allaire)</div>\n",
    "\n",
    "- One-hot-encoding: vector con n elementos (siendo n el tama√±o del vocabulario), donde s√≥lo hay valor en el componente i-√©simo, correspondiente a la palabra\n",
    "- En las representaciones distribuidas (*word embeddings*), cada palabra se representa por un vector denso (de largo 50-100, por ejemplo), y se obtienen asignando valores similares a palabras que aparecen en contextos similares\n",
    "- Estas representaciones son m√°s eficientes, porque capturan mejor la noci√≥n de sinonimia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Embeddings: Word2Vec (skip-gram with negative sampling)\n",
    "\n",
    "\n",
    "_In summary, skip-gram trains a probabilistic classifier that, given a test target word w and its context window of L words, assigns a probability based on how similar this context window is to the target word. The probability is based on applying the logistic (sigmoid) function to the dot product of the embeddings of the target word with each context word. To compute this probability, we just need embeddings for each target word and context word in the vocabulary._\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/word2vec_1.png\" alt=\"Dense embeddings\" width=500  />\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/word2vec_2.png\" alt=\"Dense embeddings\" width=500  />\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word Embeddings: Word2Vec\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/word2vec_3.png\" alt=\"Dense embeddings\" width=500  />\n",
    "\n",
    "- Otros algoritmos: CBOW, fasttext, GloVe\n",
    "- Todos generan embeddings est√°ticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning (FF) para sentiment analysis\n",
    "\n",
    "<img src=\"https://github.com/pln-fing-udelar/curso_aa/raw/master/img/sentiment_analysis.png\" alt=\"Dense embeddings\" width=600  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Las redes FF reciben como entrada (y devuelven como salida) vectores de largo fijo\n",
    "- Las RNN permiten trabajar con secuencias de vectores en la entrada, y en la salida \n",
    "\n",
    "<img src=\"http://karpathy.github.io/assets/rnn/diags.jpeg\" alt=\"RNN\"  width=600 />\n",
    "\n",
    "- 1 to 1: Clasificaci√≥n de im√°genes (FF)\n",
    "- 1 to M: Describir una imagen\n",
    "- M to 1: An√°lisis de Sentimiento\n",
    "- Many to Many: Traducci√≥n autom√°tica - Clasificaci√≥n de video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Las RNN procesan un elemento a la vez, y mantienen un vector de estado que contiene la historia de la secuencia\n",
    "- Pueden verse como redes FF, donde en cada paso discreto en el tiempo corresponde a una capa\n",
    "- La visi√≥n anterior permite utilizar backpropagation para aprender los pesos\n",
    "\n",
    "\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg\" alt=\"RNN\"  width=600 />\n",
    "\n",
    "- $x_t$ es la entrada en el paso $t$\n",
    "- $s_t$ es el estado en el paso $t$ (la \"memoria\" de la red)\n",
    "- la salida $y_t$ s√≥lo depende del estado y la entrada actual\n",
    "- En estas redes, las capas comparten los mismos pesos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Una RNN b√°sica tiene \n",
    "    - un vector $h$, llamado _estado_. \n",
    "    - una matriz $W_{hh}$ con los pesos utilizados al ajustar el vector de estado y obtener un estado nuevo\n",
    "    - una matriz $W_{xh}$ con los pesos utilizadols al ajustar el vector de estado con las entradas de cada paso\n",
    "    - una matriz $W_{hy}$ que relaciona al estado con las salidas\n",
    "    \n",
    "- En cada paso, se ajusta el estado utilizando la matriz de pesos y la entrada\n",
    "\n",
    "$$h_t = \\text{tanh}(W_{hh}h_{t-1} + W_{xh}x_{t})$$\n",
    "\n",
    "- ... y se devuelve la salida\n",
    "\n",
    "$$ y_t = W_{hy} h_{t-1}$$\n",
    "\n",
    "- Las RNN pueden verse como capas, y por lo tanto... hay Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Algunos problemas:\n",
    "    - No son buenas recordando dependencias *long-term* \n",
    "    - Durante la backpropagation, surgen problemas de gradientes que desaparecen (vanishing gradients) o crecen demasiado (exploding gradients)\n",
    "\n",
    "- Algunas formas de evituarlos:\n",
    "    - Nuevas arquitecturas (GRU, LSTMS)\n",
    "    - Otras funciones de activaci√≥n (ReLUs)\n",
    "    - Formas alternativas de entrenarlas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTMs\n",
    "\n",
    "- Las Long Short Term Memory (LSTM) son las redes recurrentes m√°s utilizadas hoy\n",
    "- La arquitectura es similar a las RNN, pero el c√°lculo del nuevo estado es un poco m√°s complejo\n",
    "- Est√°n dise√±adas para recordar dependencias lejanas en el tiempo\n",
    "- Utilizan mecanismos de \"gates\" para ver qu√© informaci√≥n se mantiene y cu√°l se agrega/elimina al estado en cada paso\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" alt=\"RNN\"  width=400/>\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" alt=\"RNN\"  width=400 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redes recurrentes para PLN: Modelos de Lenguaje\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/rnn_language_model.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Modelo de lenguaje: predecir la siguiente palabra dadas las anteriores\n",
    "- Permite expresar la noci√≥n \"probabilidad de una oraci√≥n\".\n",
    "- Teacher forcing: siempre utilizamos el texto original para las palabras anteriores a la cactual\n",
    "- Se entrena minimizando la funci√≥n de entrop√≠a cruzada en el promedio de las instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redes recurrentes para PLN: Clasificaci√≥n secuencial\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/pos_with_rnn.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "\n",
    "- En cada paso se elige (utilizando softmax) el tag m√°s probable para cada palabra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redes recurrentes para PLN: Generaci√≥n autorregresiva\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/autoregressive_generation.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Empezar con \\<s\\>\n",
    "- Muestrear una palabra de la salida\n",
    "- Seguir generando hasta llegar a \\</s\\> o a cierto l√≠mite de largo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformers (Attention is all you need)\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/transformer_language_model.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Arquitectura diferente a las RNN, pero...\n",
    "- El funcionamiento es el mismo\n",
    "- Ventaja: se puede procesar cada √≠tem en paralelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generaci√≥n contextual y resumen\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/summarization_with_transformers.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Generaci√≥n contextual: la entrada es un prefijo y pedimos al modelo que complete\n",
    "- Resumen: entrenamos el modelo con instancias que son art√≠culos y sus res√∫menes, concatenados\n",
    "- Utilizamos estas instancias para entrenar un modelo de lenguaje autorregresivo (igual que antes!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traducci√≥n autom√°tica con modelos encoder-decoder\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/encoder_decoder.png\" alt=\"\"  style=\"width: 600px;\" />\n",
    "\n",
    "- El codificador recibe una secuencia de entrada $x_1^n$ y devuelve representaciones contextuales $h^n_1$ (e.g. usando RNN o transformers)\n",
    "- Se genera un contexto $c$ que es funci√≥n de $h^n_1$\n",
    "- A partir del contexto se genera la salida $y^m_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traducci√≥n autom√°tica con modelos encoder-decoder\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/encoder_decoder_mt.png\" alt=\"\"  style=\"width: 600px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modelos Lenguajes preentrenados y fine tuning\n",
    "\n",
    "- Transfer learning: tomar conocimiento de un dominio y trasladarlo a otro\n",
    "- Pretraining: aprender representaci√≥n para palabras (u otros objetos) a partir de cantidades muy grandes de texto\n",
    "- Fine-tuning: mejorar las representaciones utilizando ejemplos adecuados a una tarea m√°s espec√≠fica (e.g. b√∫squeda de respuestas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ELMo y ULMFit (2018)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/elmo_structure.png\" alt=\"ELMo\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Los word embeddings de word2vec son _est√°ticos_\n",
    "- Embeddings from Language Model: la soluci√≥n a la polisemia. Secuencia de palabras $\\to$ secuencia de embeddings\n",
    "- Una misma palabra tiene diferentes representaciones dependiendo del contexto\n",
    "- ULMFit: Pretraining y Transfer Learning para el PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BERT (2019)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/bert.png\" alt=\"BERT\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Bidirectional Transformer Encoders\n",
    "- Basados en Transformers\n",
    "- Entrenado en dos tareas: enmascarar palabras y predicci√≥n de pr√≥xima oraci√≥n\n",
    "- Resultado: Contextual embeddings (igual que ELMo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transfer Learning con BERT: clasificaci√≥n de secuencias\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/BERT_clasificacion_de_secuencias.png\" alt=\"BERT\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Caracter especial en la entrada \\[CLS\\]\n",
    "- Su embedding representa a toda la entrada\n",
    "- Se puede utilizar como entrada para un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prompting\n",
    "\n",
    "_Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general._\n",
    "\n",
    "(Brown et al.,Language Models are Few-Shot Learners,2020)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Open source Software\n",
    "\n",
    "- Gran parte del √©xito de las aplicaci√≥n de redes neuronales se debe a que todas las bibliotecas son de c√≥digo abierto\n",
    "\n",
    "- Principales caracter√≠sticas:\n",
    "    - Permiten acelerar c√°lculos matriciales utilizandos GPUs\n",
    "    - Permiten calcular autom√°ticamente los gradientes \n",
    "    - Permiten realizar especificaciones de alto nivel de las redes neuronales\n",
    "  \n",
    "\n",
    "- [Aqu√≠ algunas muy populares](https://www.upgrad.com/blog/top-deep-learning-frameworks/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenerativeAI (?)\n",
    "\n",
    "[Leer... y pensar](https://en.wikipedia.org/wiki/Generative_artificial_intelligence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Referencias\n",
    "\n",
    "- [Deep Learning]((https://s3.us-east-2.amazonaws.com/hkg-website-assets/static/pages/files/DeepLearning.pdf)), LeCun, Bengio, Hinton. 2015. Science.\n",
    "- [Notas del curso \"Aprendizaje Profundo para Visi√≥n Artificial\"](https://iie.fing.edu.uy/~mdelbra/DL2018/slides/c6.pdf), Mauricio Delbracio, Jos√© Lezama, Guillermo Carbajal. Fing, UdelaR.\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), A. Karpathy\n",
    "- [Recurrent Neural Networks Tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/), Denny Britz.\n",
    "- [Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), Chris Olah.\n",
    "- [ConvNets: a modular perspective](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/), Chris Olah\n",
    "- [Speech and Language Processing (3rd ed. draft), cap√≠tulos 6 al 11](https://web.stanford.edu/~jurafsky/slp3/), Dan Jurafsky & James Martin\n",
    "- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165), Brown et al.\n",
    "\n",
    "- [Deep Learning Fundamentals](https://lightning.ai/courses/deep-learning-fundamentals/) curso online de S.Rashka\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prompting\n",
    "\n",
    "- [OpenAI](https://beta.openai.com/playground/p/default-qa?model=text-davinci-002)\n",
    "- [DALL-E](https://labs.openai.com/)\n",
    "- [Deep AI Text Generator](https://deepai.org/machine-learning-model/text-generator)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
